{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee2cbb5-c4c7-41d1-aff3-83f484cac0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scraping page 1...\n",
      "\n",
      "Scraping page 2...\n",
      "\n",
      "Scraping page 3...\n",
      "\n",
      "Scraping page 4...\n",
      "\n",
      "Scraping page 5...\n",
      "\n",
      "Scraping page 6...\n",
      "\n",
      "Scraping page 7...\n",
      "\n",
      "Scraping page 8...\n",
      "\n",
      "Scraping page 9...\n",
      "\n",
      "Scraping page 10...\n",
      "\n",
      "Scraping page 11...\n",
      "\n",
      "Scraping page 12...\n",
      "\n",
      "Scraping page 13...\n",
      "\n",
      "Scraping page 14...\n",
      "\n",
      "Scraping page 15...\n",
      "\n",
      "Scraping page 16...\n",
      "\n",
      "Scraping page 17...\n",
      "\n",
      "Scraping page 18...\n",
      "\n",
      "Scraping page 19...\n",
      "\n",
      "Scraping page 20...\n",
      "\n",
      "Scraped 400 job listings.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument(\"--disable-infobars\")\n",
    "options.add_argument(\"user-agent=Mozilla/5.0\")\n",
    "driver = webdriver.Chrome(options=options)\n",
    "wait = WebDriverWait(driver, 15)\n",
    "\n",
    "job_data, base_url = [], \"https://www.naukri.com/data-analyst-jobs-in-india-\"\n",
    "\n",
    "for page in range(1, 21):\n",
    "    print(f\"\\nScraping page {page}...\")\n",
    "    try:\n",
    "        driver.get(base_url + str(page))\n",
    "        wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"div.row3\")))\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "\n",
    "        for job in driver.find_elements(By.CSS_SELECTOR, \"div.row3\"):\n",
    "            get_text = lambda selector: (job.find_element(By.CSS_SELECTOR, selector).text.strip()\n",
    "                                         if len(job.find_elements(By.CSS_SELECTOR, selector)) else \"\")\n",
    "            experience = get_text(\"span.expwdth\")\n",
    "            location = get_text(\"span.locWdth\")\n",
    "            description = (job.find_element(By.XPATH, \"./following-sibling::div[contains(@class, 'row4')]\").text.strip()\n",
    "                           if len(job.find_elements(By.XPATH, \"./following-sibling::div[contains(@class, 'row4')]\")) else \"\")\n",
    "            job_data.append({\"Experience\": experience, \"Location\": location, \"Description\": description})\n",
    "    except Exception as e:\n",
    "        print(f\"Error on page {page}: {e}\")\n",
    "\n",
    "    time.sleep(random.uniform(2, 5))\n",
    "\n",
    "driver.quit()\n",
    "df = pd.DataFrame(job_data)\n",
    "print(f\"\\nScraped {len(df)} job listings.\")\n",
    "df.to_csv(\"naukri_dataanalyst_scraped.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da2ddd5-720a-451c-8d3a-45d149df3256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
